# Tell VS Code which interpreter to use
# Press Ctrl+Shift+P (or Cmd+Shift+P on macOS) to open the Command Palette.
# Type “Python: Select Interpreter” and hit Enter.
# You’ll see a list of detected interpreters. Look for the one that points to your venv, e.g.:
# .venv\Scripts\python.exe      (Windows)
# .venv/bin/python              (macOS/Linux)

"""
Build with AI: Creating AI Agents with GPT-5
All examples use Python and the OpenAI client.

Prereqs:
  pip install openai
  pip install python-dotenv
  export API_KEY = os.environ[...]
"""
import os
os.system('cls') # Windows
os.system('clear') # Linux

from openai import OpenAI
from dotenv import load_dotenv, find_dotenv
from agents import Agent, Runner, function_tool, ModelSettings
from dataclasses import dataclass
from datetime import datetime
import requests

# retrieve OpenAI API key
# Finds .env file
dotenvfile = find_dotenv()
if True:
    print("Current folder: ",os.getcwd())
    print("DotEnv file folder: ",dotenvfile)
    print("\n")
# read local .env file
_ = load_dotenv(dotenvfile) 

# OpenAI instanciation
token = os.environ["OPENAI_API_KEY"]
UsingGitHub = (token[:10]=="github_pat")
print (f"Token: {token} - Using GitHub: {UsingGitHub}")
print("\n")

endpoint = "https://models.github.ai/inference"
model = "gpt-5" # "openai/gpt-4o" # "gpt-4o" # 

if UsingGitHub:
    client = OpenAI(
        base_url=endpoint,
        api_key=token,
    )
else:
    client = OpenAI(
            api_key=token,
    )

if False: # LLM model test
    question="Tell me a fun fact about the ocean."
    response = client.chat.completions.create(
        model=model,
        messages=[{"role": "user", "content": question}]
    )
    print(f"Question: ",question)
    print(f"Test Response using model {model}: ",response.choices[0].message.content)
    print("\n")

# # ---------------------------------------------------------------------------
# # LESSON 2 (Build a Basic Agent with Tool Calling)
# # ---------------------------------------------------------------------------
@dataclass
class WeatherInfo:
    city: str
    country: str
    temp_f: float
    condition: str

@function_tool # See Fnction_Tool Copilot explanation for details on what this decorator does. It turns the function into a tool that can be called by the agent.
def get_weather_forecast(city: str):
    """Fetch weather info using the Weather API - https://www.weatherapi.com/
       Create an account and generate your API key - https://www.weatherapi.com/my/ 
    """
    API_KEY = api_key=os.environ['WEATHER_API_KEY']
    WEATHER_BASE_URL = 'https://api.weatherapi.com/v1/current.json'

    try:
        today = datetime.today().strftime('%Y-%m-%d')
        params = {"q": city, "aqi": "no", "key": API_KEY}
        
        #construct request and call api
        response = requests.get(WEATHER_BASE_URL, params=params)
        response.raise_for_status()

        data = response.json()

        # Basic validation
        if "location" not in data or "current" not in data:
            return f"Could not retrieve weather for '{city}'. Try a more specific place name."

        weather = WeatherInfo(
            city=data["location"]["name"],
            country=data["location"]["country"],
            temp_f=float(data["current"]["temp_f"]),
            condition=data["current"]["condition"]["text"]
        )

        weather_report = [f"Real-time weather report for {today}:"]

        weather_report.append(
                f"   - City: {weather.city}"
                f"   - Country: {weather.country}"
                f"   - Temperature: {weather.temp_f:.1f} °F"
                f"   - Weather Conditions: {weather.condition}"
            )

        return "\n".join(weather_report)
    except requests.exceptions.RequestException as e:
        return f"Error fetching weather data: {str(e)}"

trip_agent = Agent(
    name="Trip Coach",
    instructions=(
        "You help travelers plan by checking real-time weather."
        "When asked about weather or packing, call the get_weather_forecast tool."
        "Make sure you have access to real-time weather data to make your recommendations."
    ),
    model="gpt-5",
    tools=[get_weather_forecast],
    # ---------- Lesson 3: steer behavior----------
    model_settings=ModelSettings(
        reasoning={"effort": "low"},   # minimal | low | medium | high 
        extra_body={"text":{"verbosity":"low"}}  # low | medium | high
    )
)

# Trying to show the registration metadata generated by function_tool
if False:
    # Print the object itself
    print("\nObject representation:")
    print(get_weather_forecast)
    # Print vars/dict
    print("\nObject vars:")
    print(vars(get_weather_forecast) if hasattr(get_weather_forecast, '__dict__') else "No __dict__")
    print("\n")

city = "Winter Garden, FL" # Horizon West FL did not worked correctly

if False: # Test Get Weather Forecast Function
    weather_result = get_weather_forecast(city) # This only works by removing the @function_tool decorator, since it turns the function into a tool object. See CallingAFunctionToolDecoratedFunction.md
    print(f"Weather forecast for {city}:\n{weather_result}\n")

if True: # Actual Exercise test
    result = Runner.run_sync(trip_agent, f"""Headed to {city} today. What weather should I expect and 
                                             what is the exact temperature right now? 
                                             Also, what types of clothes should I pack""")
    print(result.final_output)
    
    from pprint import pprint
    import rich # Requires: pip install rich
    if False : # Use pythons default pretty print instead of Rich library print
        print ("\nRaw Result")
        pprint(result)
        print ("\nRaw Responses")
        pprint(result.raw_responses)
        print ("\nItems")
        pprint(result.new_items)
    else : # Use Rich library for better formatting
        print ("\nRaw Result")
        rich.print(result)
        print ("\nRaw Responses")
        rich.print(result.raw_responses)
        print ("\nItems")
        rich.print(result.new_items)